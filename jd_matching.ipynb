{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load CSV data\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    return \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize and encode text\n",
    "def encode_text(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    return torch.tensor(indexed_tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Match job descriptions based on prompt\n",
    "def match_job_descriptions(csv_data, prompt):\n",
    "    prompt_encoded = encode_text(preprocess_text(prompt))\n",
    "    prompt_embedding = model(prompt_encoded)[0].detach().numpy()[0]\n",
    "    similarities = []\n",
    "    for index, row in csv_data.iterrows():\n",
    "        description = row['job_description']\n",
    "        description_encoded = encode_text(preprocess_text(description))\n",
    "        description_embedding = model(description_encoded)[0].detach().numpy()[0]\n",
    "        similarity = cosine_similarity([prompt_embedding], [description_embedding])[0][0]\n",
    "        similarities.append((row['job_id'], similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities\n",
    "\n",
    "# Split data into train, eval, and test sets\n",
    "def split_data(data, test_size=0.2, eval_size=0.2):\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size)\n",
    "    train_data, eval_data = train_test_split(train_data, test_size=eval_size)\n",
    "    return train_data, eval_data, test_data\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return accuracy_score(labels, predictions)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV data\n",
    "    csv_data = load_csv(\"job_descriptions.csv\")\n",
    "\n",
    "    # Sample prompt\n",
    "    prompt = \"Data scientist with expertise in machine learning and Python\"\n",
    "\n",
    "    # Split data into train, eval, and test sets\n",
    "    train_data, eval_data, test_data = split_data(csv_data)\n",
    "\n",
    "    # Match job descriptions based on the prompt\n",
    "    matched_jobs_train = match_job_descriptions(train_data, prompt)\n",
    "    matched_jobs_eval = match_job_descriptions(eval_data, prompt)\n",
    "    matched_jobs_test = match_job_descriptions(test_data, prompt)\n",
    "\n",
    "    # Display top matched jobs\n",
    "    print(\"Top matched jobs on training set:\")\n",
    "    for job_id, similarity in matched_jobs_train[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on evaluation set:\")\n",
    "    for job_id, similarity in matched_jobs_eval[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on testing set:\")\n",
    "    for job_id, similarity in matched_jobs_test[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    # Calculate accuracy on the test set (for demonstration purposes)\n",
    "    # In reality, you would need labeled data to calculate accuracy\n",
    "    test_predictions = [1 if similarity > 0.5 else 0 for _, similarity in matched_jobs_test]\n",
    "    test_labels = [1] * len(test_predictions)  # Example labels, replace with actual labels\n",
    "    accuracy = calculate_accuracy(test_predictions, test_labels)\n",
    "    print(f\"Accuracy on the test set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Load CSV data\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    return \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize and encode text\n",
    "def encode_text(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    return torch.tensor(indexed_tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Match job descriptions based on prompt\n",
    "def match_job_descriptions(csv_data, prompt):\n",
    "    prompt_encoded = encode_text(preprocess_text(prompt))\n",
    "    with torch.no_grad():\n",
    "        prompt_embedding = model(prompt_encoded)[0][:, 0, :].numpy()\n",
    "    similarities = []\n",
    "    for index, row in csv_data.iterrows():\n",
    "        description = row['job_description']\n",
    "        description_encoded = encode_text(preprocess_text(description))\n",
    "        with torch.no_grad():\n",
    "            description_embedding = model(description_encoded)[0][:, 0, :].numpy()\n",
    "        similarity = cosine_similarity(prompt_embedding, description_embedding)[0][0]\n",
    "        similarities.append((row['job_id'], similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities\n",
    "\n",
    "# Split data into train, eval, and test sets\n",
    "def split_data(data, test_size=0.2, eval_size=0.2):\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size)\n",
    "    train_data, eval_data = train_test_split(train_data, test_size=eval_size)\n",
    "    return train_data, eval_data, test_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV data\n",
    "    csv_data = load_csv(\"job_descriptions.csv\")\n",
    "\n",
    "    # Sample prompt\n",
    "    prompt = \"Data scientist with expertise in machine learning and Python\"\n",
    "\n",
    "    # Split data into train, eval, and test sets\n",
    "    train_data, eval_data, test_data = split_data(csv_data)\n",
    "\n",
    "    # Match job descriptions based on the prompt\n",
    "    matched_jobs_train = match_job_descriptions(train_data, prompt)\n",
    "    matched_jobs_eval = match_job_descriptions(eval_data, prompt)\n",
    "    matched_jobs_test = match_job_descriptions(test_data, prompt)\n",
    "\n",
    "    # Display top matched jobs\n",
    "    print(\"Top matched jobs on training set:\")\n",
    "    for job_id, similarity in matched_jobs_train[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on evaluation set:\")\n",
    "    for job_id, similarity in matched_jobs_eval[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on testing set:\")\n",
    "    for job_id, similarity in matched_jobs_test[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
