{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load CSV data\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    return \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize and encode text\n",
    "def encode_text(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    return torch.tensor(indexed_tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Match job descriptions based on prompt\n",
    "def match_job_descriptions(csv_data, prompt):\n",
    "    prompt_encoded = encode_text(preprocess_text(prompt))\n",
    "    prompt_embedding = model(prompt_encoded)[0].detach().numpy()[0]\n",
    "    similarities = []\n",
    "    for index, row in csv_data.iterrows():\n",
    "        description = row['job_description']\n",
    "        description_encoded = encode_text(preprocess_text(description))\n",
    "        description_embedding = model(description_encoded)[0].detach().numpy()[0]\n",
    "        similarity = cosine_similarity([prompt_embedding], [description_embedding])[0][0]\n",
    "        similarities.append((row['job_id'], similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities\n",
    "\n",
    "# Split data into train, eval, and test sets\n",
    "def split_data(data, test_size=0.2, eval_size=0.2):\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size)\n",
    "    train_data, eval_data = train_test_split(train_data, test_size=eval_size)\n",
    "    return train_data, eval_data, test_data\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return accuracy_score(labels, predictions)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV data\n",
    "    csv_data = load_csv(\"job_descriptions.csv\")\n",
    "\n",
    "    # Sample prompt\n",
    "    prompt = \"Data scientist with expertise in machine learning and Python\"\n",
    "\n",
    "    # Split data into train, eval, and test sets\n",
    "    train_data, eval_data, test_data = split_data(csv_data)\n",
    "\n",
    "    # Match job descriptions based on the prompt\n",
    "    matched_jobs_train = match_job_descriptions(train_data, prompt)\n",
    "    matched_jobs_eval = match_job_descriptions(eval_data, prompt)\n",
    "    matched_jobs_test = match_job_descriptions(test_data, prompt)\n",
    "\n",
    "    # Display top matched jobs\n",
    "    print(\"Top matched jobs on training set:\")\n",
    "    for job_id, similarity in matched_jobs_train[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on evaluation set:\")\n",
    "    for job_id, similarity in matched_jobs_eval[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on testing set:\")\n",
    "    for job_id, similarity in matched_jobs_test[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    # Calculate accuracy on the test set (for demonstration purposes)\n",
    "    # In reality, you would need labeled data to calculate accuracy\n",
    "    test_predictions = [1 if similarity > 0.5 else 0 for _, similarity in matched_jobs_test]\n",
    "    test_labels = [1] * len(test_predictions)  # Example labels, replace with actual labels\n",
    "    accuracy = calculate_accuracy(test_predictions, test_labels)\n",
    "    print(f\"Accuracy on the test set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Load CSV data\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "allowed_word_types = [\"N\", \"V\", \"J\", \"R\"]  # Nouns, Verbs, Adjectives, Adverbs\n",
    "\n",
    "def preprocess_text(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    tagged_words = pos_tag(word_tokens)\n",
    "    cleaned_words = []\n",
    "    for word, tag in tagged_words:\n",
    "        if word.lower() not in stop_words and tag[0] in allowed_word_types:\n",
    "            cleaned_words.append(word)\n",
    "    cleaned_text = \" \".join(cleaned_words)\n",
    "    return \"[CLS] \" + cleaned_text + \" [SEP]\"\n",
    "\n",
    "# Tokenize and encode text\n",
    "def encode_text(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    return torch.tensor(indexed_tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Match job descriptions based on prompt\n",
    "def match_job_descriptions(csv_data, prompt):\n",
    "    prompt_encoded = encode_text(preprocess_text(prompt))\n",
    "    with torch.no_grad():\n",
    "        prompt_embedding = model(prompt_encoded)[0][:, 0, :].numpy()\n",
    "    similarities = []\n",
    "    for index, row in csv_data.iterrows():\n",
    "        description = row['job_description']\n",
    "        description_encoded = encode_text(preprocess_text(description))\n",
    "        with torch.no_grad():\n",
    "            description_embedding = model(description_encoded)[0][:, 0, :].numpy()\n",
    "        similarity = cosine_similarity(prompt_embedding, description_embedding)[0][0]\n",
    "        similarities.append((row['job_id'], similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities\n",
    "\n",
    "# Split data into train, eval, and test sets\n",
    "def split_data(data, test_size=0.2, eval_size=0.2):\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size)\n",
    "    train_data, eval_data = train_test_split(train_data, test_size=eval_size)\n",
    "    return train_data, eval_data, test_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV data\n",
    "    csv_data = load_csv(\"job_descriptions.csv\")\n",
    "\n",
    "    # Sample prompt\n",
    "    prompt = \"Data scientist with expertise in machine learning and Python\"\n",
    "\n",
    "    # Split data into train, eval, and test sets\n",
    "    train_data, eval_data, test_data = split_data(csv_data)\n",
    "\n",
    "    # Match job descriptions based on the prompt\n",
    "    matched_jobs_train = match_job_descriptions(train_data, prompt)\n",
    "    matched_jobs_eval = match_job_descriptions(eval_data, prompt)\n",
    "    matched_jobs_test = match_job_descriptions(test_data, prompt)\n",
    "\n",
    "    # Display top matched jobs\n",
    "    print(\"Top matched jobs on training set:\")\n",
    "    for job_id, similarity in matched_jobs_train[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on evaluation set:\")\n",
    "    for job_id, similarity in matched_jobs_eval[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n",
    "\n",
    "    print(\"Top matched jobs on testing set:\")\n",
    "    for job_id, similarity in matched_jobs_test[:5]:\n",
    "        print(f\"Job ID: {job_id}, Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Load DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load CSV data\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    return \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Extract features from job description\n",
    "def extract_features(text):\n",
    "    doc = nlp(text)\n",
    "    skills = [entity.text for entity in doc.ents if entity.label_ == 'SKILL']\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == 'GPE']\n",
    "    experiences = [entity.text for entity in doc.ents if entity.label_ == 'EXPERIENCE']\n",
    "    designations = [entity.text for entity in doc.ents if entity.label_ == 'TITLE']\n",
    "    responsibilities = [chunk.text for chunk in doc.noun_chunks if 'responsibility' in chunk.text.lower()]\n",
    "    return skills, locations, experiences, designations, responsibilities\n",
    "\n",
    "# Tokenize and encode text\n",
    "def encode_text(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    return torch.tensor(indexed_tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Extract features and encode text for training\n",
    "def preprocess_data(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in data.iterrows():\n",
    "        skills, _, _, _, _ = extract_features(row['job_description'])\n",
    "        features.append(encode_text(preprocess_text(row['job_description'])))\n",
    "        # Example label - 1 if 'Data Scientist' is in the designation, else 0\n",
    "        labels.append(1 if 'Data Scientist' in row['job_description'] else 0)\n",
    "    return torch.cat(features, dim=0), torch.tensor(labels)\n",
    "\n",
    "# Neural network model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = model\n",
    "        self.fc = nn.Linear(768, 1)  # Output size is 1 for binary classification\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        outputs = self.bert(input_ids)[0][:, 0, :]  # Use CLS token output\n",
    "        return torch.sigmoid(self.fc(outputs))\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, eval_loader, num_epochs=5, lr=0.001):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    train_accuracies = []\n",
    "    eval_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.round(outputs).cpu().detach().numpy(), labels.cpu().detach().numpy()\n",
    "            correct_train += (predicted == labels.numpy()).sum()\n",
    "            total_train += len(labels)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accuracies.append(correct_train / total_train)\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0.0\n",
    "        correct_eval = 0\n",
    "        total_eval = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in eval_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "                eval_loss += loss.item()\n",
    "                _, predicted = torch.round(outputs).cpu().detach().numpy(), labels.cpu().detach().numpy()\n",
    "                correct_eval += (predicted == labels.numpy()).sum()\n",
    "                total_eval += len(labels)\n",
    "\n",
    "        eval_losses.append(eval_loss / len(eval_loader))\n",
    "        eval_accuracies.append(correct_eval / total_eval)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Eval Loss: {eval_losses[-1]:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracies[-1]:.4f}, \"\n",
    "              f\"Eval Accuracy: {eval_accuracies[-1]:.4f}\")\n",
    "\n",
    "    return train_losses, eval_losses, train_accuracies, eval_accuracies\n",
    "\n",
    "# Plot accuracy and loss\n",
    "def plot_metrics(train_losses, eval_losses, train_accuracies, eval_accuracies):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(eval_losses, label='Eval Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Evaluation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(eval_accuracies, label='Eval Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Evaluation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV data\n",
    "    csv_data = load_csv(\"job_descriptions.csv\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X, y = preprocess_data(csv_data)\n",
    "\n",
    "    # Split data into train, eval, and test sets\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2)\n",
    "    train_loader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=16, shuffle=True)\n",
    "    eval_loader = torch.utils.data.DataLoader(list(zip(X_eval, y_eval)), batch_size=16)\n",
    "\n",
    "    # Initialize model\n",
    "    model = Model()\n",
    "\n",
    "    # Train the model\n",
    "    train_losses, eval_losses, train_accuracies, eval_accuracies = train_model(model, train_loader, eval_loader)\n",
    "\n",
    "    # Plot metrics\n",
    "    plot_metrics(train_losses, eval_losses, train_accuracies, eval_accuracies)\n",
    "\n",
    "    # Predict on test set\n",
    "    X_test, y_test = preprocess_data(test_data)\n",
    "    test_loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=16)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.round(outputs).cpu().detach().numpy(), labels.cpu().detach().numpy()\n",
    "            predictions.extend(predicted)\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy on the test set: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
