{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restart_kernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)\n",
    "\n",
    "# Call the function to restart the kernel\n",
    "restart_kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (16,768) and (19,768) not aligned: 768 (dim 1) != 19 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m resume \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperienced software engineer with expertise in Python, Java, and machine learning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m job_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe are looking for a software engineer proficient in Python, Java, and machine learning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 49\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[43mkeyword_matching_resume_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResume matches job description.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m, in \u001b[0;36mkeyword_matching_resume_job\u001b[1;34m(resume, job_description, threshold)\u001b[0m\n\u001b[0;32m     36\u001b[0m job_description_encoding \u001b[38;5;241m=\u001b[39m encode_text(job_description)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity between the two encodings\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description_encoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarity_score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(vec1, vec2)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcosine_similarity\u001b[39m(vec1, vec2):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    Compute cosine similarity between two vectors\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     dot_product \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     norm_vec1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(vec1)\n\u001b[0;32m     26\u001b[0m     norm_vec2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(vec2)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (16,768) and (19,768) not aligned: 768 (dim 1) != 19 (dim 0)"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained DistilBERT model and tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def encode_text(text):\n",
    "    \"\"\"\n",
    "    Tokenize and encode text using DistilBERT tokenizer\n",
    "    \"\"\"\n",
    "    tokenized_text = tokenizer.encode(text, add_special_tokens=True)\n",
    "    input_ids = torch.tensor([tokenized_text])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]\n",
    "    return last_hidden_states.numpy()\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity\n",
    "\n",
    "def keyword_matching_resume_job(resume, job_description, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Perform keyword matching between resume and job description\n",
    "    \"\"\"\n",
    "    # Encode resume and job description\n",
    "    resume_encoding = encode_text(resume)\n",
    "    job_description_encoding = encode_text(job_description)\n",
    "    \n",
    "    # Compute cosine similarity between the two encodings\n",
    "    similarity_score = cosine_similarity(resume_encoding, job_description_encoding)\n",
    "    \n",
    "    if similarity_score >= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "resume = \"Experienced software engineer with expertise in Python, Java, and machine learning.\"\n",
    "job_description = \"We are looking for a software engineer proficient in Python, Java, and machine learning.\"\n",
    "match = keyword_matching_resume_job(resume, job_description)\n",
    "if match:\n",
    "    print(\"Resume matches job description.\")\n",
    "else:\n",
    "    print(\"Resume does not match job description.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load data from CSV files\n",
    "resume_data = pd.read_csv('resume_data.csv')\n",
    "job_description_data = pd.read_csv('job_description_data.csv')\n",
    "\n",
    "# Split data into training and evaluation sets\n",
    "resume_train, resume_eval = train_test_split(resume_data, test_size=0.2, random_state=42)\n",
    "job_description_train, job_description_eval = train_test_split(job_description_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fine-tune DistilBERT model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Prepare training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Define evaluation function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=resume_train,\n",
    "    eval_dataset=resume_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on job description data\n",
    "eval_result = trainer.evaluate(eval_dataset=job_description_eval)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Accuracy:\", eval_result['eval_accuracy'])\n",
    "print(\"Precision:\", eval_result['eval_precision'])\n",
    "print(\"Recall:\", eval_result['eval_recall'])\n",
    "print(\"F1-score:\", eval_result['eval_f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load data from CSV files\n",
    "resume_data = pd.read_csv('resume_data.csv')\n",
    "job_description_data = pd.read_csv('job_description_data.csv')\n",
    "\n",
    "# Split data into training and evaluation sets\n",
    "resume_train, resume_eval = train_test_split(resume_data, test_size=0.2, random_state=42)\n",
    "job_description_train, job_description_eval = train_test_split(job_description_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fine-tune DistilBERT model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Prepare training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Define evaluation function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=resume_train,\n",
    "    eval_dataset=resume_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Prepare evaluation dataset for job descriptions\n",
    "eval_input_ids = tokenizer(job_description_eval['job_description'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Evaluate the model\n",
    "eval_output = trainer.predict(eval_input_ids)\n",
    "\n",
    "# Get predicted labels\n",
    "pred_labels = torch.argmax(eval_output.predictions, axis=1).tolist()\n",
    "\n",
    "# Print matching scores for matching resumes and job descriptions\n",
    "for i, (resume_id, job_id, company, position_title) in enumerate(zip(job_description_eval['job_id'], job_description_eval['company'], job_description_eval['position_title'], job_description_eval['resume_str'])):\n",
    "    if pred_labels[i] == 1:\n",
    "        print(f\"Resume ID: {resume_id}, Job ID: {job_id}, Company: {company}, Position Title: {position_title}, Matching Score: {eval_output.predictions[i][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load data from CSV files\n",
    "resume_data = pd.read_csv('resume_data.csv')\n",
    "job_description_data = pd.read_csv('job_description_data.csv')\n",
    "\n",
    "# Split data into training and evaluation sets\n",
    "resume_train, resume_eval = train_test_split(resume_data, test_size=0.2, random_state=42)\n",
    "job_description_train, job_description_eval = train_test_split(job_description_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fine-tune DistilBERT model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Prepare training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Define evaluation function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=resume_train,\n",
    "    eval_dataset=resume_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model and print performance metrics during training\n",
    "trainer.train()\n",
    "train_result = trainer.evaluate()\n",
    "print(\"Training performance metrics:\", train_result)\n",
    "\n",
    "# Prepare evaluation dataset for job descriptions\n",
    "eval_input_ids = tokenizer(job_description_eval['job_description'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Evaluate the model on job description evaluation dataset\n",
    "eval_output = trainer.predict(eval_input_ids)\n",
    "eval_result = compute_metrics(eval_output)\n",
    "print(\"Evaluation performance metrics:\", eval_result)\n",
    "\n",
    "# Print matching scores for matching resumes and job descriptions\n",
    "for i, (resume_id, job_id, company, position_title) in enumerate(zip(job_description_eval['job_id'], job_description_eval['company'], job_description_eval['position_title'], job_description_eval['resume_str'])):\n",
    "    if eval_output.predictions[i][1] >= 0.5:\n",
    "        print(f\"Resume ID: {resume_id}, Job ID: {job_id}, Company: {company}, Position Title: {position_title}, Matching Score: {eval_output.predictions[i][1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
